{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21463d01-0e38-4f04-838f-4653556f2a1c",
   "metadata": {},
   "source": [
    "<h1>Hugging Face</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b22780f-4d7d-4653-91bb-bd7073596d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b89bd5-91bc-4a63-921b-da9dd22a1943",
   "metadata": {},
   "source": [
    "<h3>Searching for a model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57559a1a-af85-4263-b270-1bb0ab7d8b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1231czx/llama3_it_ultra_list_and_bold500\n"
     ]
    }
   ],
   "source": [
    "# Create the instance of the API\n",
    "api = HfApi()\n",
    "\n",
    "# Return the filtered list from the Hub\n",
    "models = api.list_models(\n",
    "    filter=\"text-classification\",\n",
    "    sort=\"downloads\",\n",
    "    direction=-1,\n",
    "  \tlimit=5\n",
    ")\n",
    "\n",
    "# Store as a list\n",
    "modelList = list(models)\n",
    "\n",
    "# View top search result\n",
    "print(modelList[0].modelId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aa1803-0604-4a06-bfea-3ca8118391dc",
   "metadata": {},
   "source": [
    "<h3>Saving a model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9898988c-f452-45c6-8c9b-9c7b9b6a1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ec93175-85a4-44bc-a125-edd78b137424",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelId = \"distilbert-base-uncased-finetuned-sst-2-english\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7485211-a64c-4007-bb8c-7f719dc8d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the AutoModel class\n",
    "model = AutoModel.from_pretrained(modelId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0721d3ec-f921-47fc-bf8b-84bc8e840b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(save_directory=f\"models/{modelId}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539753a9-da8b-463d-8b84-ffa2fd31e1d0",
   "metadata": {},
   "source": [
    "<h3>Inspecting a dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ce1d07-31ab-4da7-bca2-841fd7417733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d706c53-ce8a-4f98-b0f6-2ad3c53e0a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_builder = load_dataset_builder(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cb628e6-e419-47a3-9766-40418e9bc538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(data_builder.info.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c85e27d-d4d8-463c-9f79-e5e8020e9f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['neg', 'pos'], id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(data_builder.info.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70c2c9ae-64d8-4f63-8085-ad1c691b1947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ff5d574-98a3-4e0e-ae3b-0c655f1f35c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "707713dd-b97b-4613-9ab5-5aa06f68ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = load_dataset(\"imdb\", split=\"train\")\n",
    "#wikipedia = load_dataset(\"wikimedia/wikipedia\", language=\"20231101.en\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2953df8a-a985-4f86-83ab-c06d6d97f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter imdb\n",
    "filtered = imdb.filter(lambda row: row['label']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4357c86-c137-46e4-98e5-e831ffc5a996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 2\n",
      "})\n",
      "I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "sliced = filtered.select(range(2))\n",
    "\n",
    "print(sliced)\n",
    "\n",
    "print(sliced[0]['text'])\n",
    "print(sliced[0]['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ceeff-ee54-4b89-a816-0e578c48786c",
   "metadata": {},
   "source": [
    "<h4>Auto classes to directly download a model</h4>\n",
    "\n",
    "<h4>AutoModel class for each type of task</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dec6187-8b40-46cf-ad6e-a7b935cffd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f80006aa-e9ec-4049-834c-f3344a4ef9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf33670-fd47-43d2-9376-f44973a8022f",
   "metadata": {},
   "source": [
    "<h4>AutoTokenizers prepare text input data</h4>\n",
    "\n",
    "<h4>Recommended to use the tokenizer paired with the model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d560ebba-67e7-4f0d-8798-b1b5c843c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c6f30a-e5ab-4fe4-b0e1-8ed50cf69e49",
   "metadata": {},
   "source": [
    "<h3>The Pipeline Module</h3>\n",
    "\n",
    "<h4>Contains all task-specific steps</h4>\n",
    "\n",
    "<h4>Best for quickly performing tasks</h4>\n",
    "\n",
    "<h4>Great for getting started</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a33e1277-8dda-4455-95a5-9dd391d5278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task-specific pipeline for each task that leverage auto classes behind the scene\n",
    "from transformers import pipeline, SummarizationPipeline, \\\n",
    "    TextClassificationPipeline, AudioClassificationPipeline, ImageSegmentationPipeline, QuestionAnsweringPipeline, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370b5688-cdcb-470f-8489-83947c4f83fb",
   "metadata": {},
   "source": [
    "<h4>Creating a pipeline</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5da1f90-f1f4-4da7-b311-b0dd58bbdafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63de8ca5-4c33-45f0-be23-b6947df5e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b43474a6-fe93-4f3d-a8af-91e7fafc0071",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e170d97-361f-4c8c-85bc-1c1b0ac3d3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997480511665344}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \"Hi, welcome to this introduction about Hugging Face\"\n",
    "\n",
    "my_pipeline(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59886295-f266-41c0-a1c1-ba6015a0647e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment using AutoClasses: POSITIVE\n"
     ]
    }
   ],
   "source": [
    "# Download the model and tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Create the pipeline\n",
    "model_pipeline = pipeline(task=\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Predict the sentiment\n",
    "output = model_pipeline(input)\n",
    "\n",
    "print(f\"Sentiment using AutoClasses: {output[0]['label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdcd4161-4c46-4794-b37e-8c935124d96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "howdy, how are you?\n"
     ]
    }
   ],
   "source": [
    "# Import the AutoTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Download the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"distilbert-base-uncased\", \n",
    "    clean_up_tokenization_spaces=True\n",
    ")\n",
    "\n",
    "# Normalize the input string\n",
    "output = tokenizer.backend_tokenizer.normalizer.normalize_str('HOWDY, how aré yoü?')\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "138ea790-c18e-4545-849d-ed43d7d8961f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT tokenizer: ['Hi', ',', 'Ġwelcome', 'Ġto', 'Ġthis', 'Ġintroduction', 'Ġabout', 'ĠHug', 'ging', 'ĠFace']\n",
      "DistilBERT tokenizer: ['hi', ',', 'welcome', 'to', 'this', 'introduction', 'about', 'hugging', 'face']\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, DistilBertTokenizer\n",
    "\n",
    "# Download the gpt tokenizer\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\n",
    "    \"gpt2\", \n",
    "    clean_up_tokenization_spaces=True\n",
    ")\n",
    "\n",
    "# Tokenize the input\n",
    "gpt_tokens = gpt_tokenizer.tokenize(input)\n",
    "\n",
    "# Repeat for distilbert\n",
    "distil_tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "    \"distilbert-base-uncased-finetuned-sst-2-english\", \n",
    "    clean_up_tokenization_spaces=True\n",
    ")\n",
    "distil_tokens = distil_tokenizer.tokenize(text=input)\n",
    "\n",
    "# Compare the output\n",
    "print(f\"GPT tokenizer: {gpt_tokens}\")\n",
    "print(f\"DistilBERT tokenizer: {distil_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3e5a397-0b4f-432d-ade7-99be594332a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHAMMEDG\\Anaconda3\\envs\\training\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.9956323504447937}]\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline\n",
    "classifier = pipeline(\n",
    "  task=\"text-classification\", \n",
    "  model=\"abdulmatinomotoso/English_Grammar_Checker\"\n",
    ")\n",
    "\n",
    "# Predict classification\n",
    "output = classifier(\"I will walk dog\")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6244c54-62c0-4f30-b249-66083b3cc970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.0052389358170330524}]\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "classifier = pipeline(task=\"text-classification\", model=\"cross-encoder/qnli-electra-base\")\n",
    "\n",
    "# Predict the output\n",
    "output = classifier(\"Where is the capital of France?, Brittany is known for their kouign-amann.\")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43156a06-3b39-4682-87f6-3020c2369cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Label: science with score: 0.903059720993042\n"
     ]
    }
   ],
   "source": [
    "# Build the zero-shot classifier\n",
    "classifier = pipeline(task=\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Create the list\n",
    "candidate_labels = [\"politics\", \"science\", \"sports\"]\n",
    "\n",
    "# Predict the output\n",
    "output = classifier(sequences=\"A 75-million-year-old Gorgosaurus fossil is the first tyrannosaur skeleton ever found with a filled stomach.\", candidate_labels=candidate_labels)\n",
    "\n",
    "print(f\"Top Label: {output['labels'][0]} with score: {output['scores'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "462ce4ed-67d9-415e-b7b4-1acfb0f16fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text length: 907\n",
      "Summary length: 473\n"
     ]
    }
   ],
   "source": [
    "# Create the summarization pipeline\n",
    "summarizer = pipeline(task=\"summarization\", model=\"cnicu/t5-small-booksum\")\n",
    "\n",
    "original_text = \"Greece has many islands, with estimates ranging from somewhere around 1,200 to 6,000, depending on the minimum size to take into account. \\\n",
    "                The number of inhabited islands is variously cited as between 166 and 227. The Greek islands are traditionally grouped into the following \\\n",
    "                clusters: the Argo-Saronic Islands in the Saronic Gulf near Athens; the Cyclades, a large but dense collection occupying the central part of \\\n",
    "                the Aegean Sea; the North Aegean islands, a loose grouping off the west coast of Turkey; the Dodecanese, another loose collection in the \\\n",
    "                southeast between Crete and Turkey; the Sporades, a small tight group off the coast of Euboea; and the Ionian Islands, chiefly located to \\\n",
    "                the west of the mainland in the Ionian Sea. Crete with its surrounding islets and Euboea are traditionally excluded from this grouping.\"\n",
    "\n",
    "# Summarize the text\n",
    "summary_text = summarizer(original_text)\n",
    "\n",
    "# Compare the length\n",
    "# Compare the length\n",
    "print(f\"Original text length: {len(original_text)}\")\n",
    "print(f\"Summary length: {len(summary_text[0]['summary_text'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a4c8b48-486d-4a6f-a2e8-fb4b7fb8801c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greece has many islands, with estimates ranging\n"
     ]
    }
   ],
   "source": [
    "# Create a short summarizer\n",
    "short_summarizer = pipeline(task=\"summarization\", model=\"cnicu/t5-small-booksum\", min_length=1, max_length=10)\n",
    "\n",
    "# Summarize the input text\n",
    "short_summary_text = short_summarizer(original_text)\n",
    "\n",
    "# Print the short summary\n",
    "print(short_summary_text[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "250d9b72-77a2-4725-b996-ed19fbf004e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greece has many islands, with estimates ranging\n",
      "Greece has many islands, with estimates ranging from somewhere around 1,200 to 6,000 depending on the minimum size to take into account. The number of inhabited islands is variously cited as between 166 and 227. The Greek islands are traditionally grouped into the following clusters: the Argo-Saronic Islands in the Saronic Gulf near Athens; the Cyclades, a large but dense collection occupying the central part of the Aegean Sea; the North Aegesan islands, an loose group\n"
     ]
    }
   ],
   "source": [
    "# Create a short summarizer\n",
    "short_summarizer = pipeline(task=\"summarization\", model=\"cnicu/t5-small-booksum\", min_length=1, max_length=10)\n",
    "\n",
    "# Summarize the input text\n",
    "short_summary_text = short_summarizer(original_text)\n",
    "\n",
    "# Print the short summary\n",
    "print(short_summary_text[0][\"summary_text\"])\n",
    "\n",
    "# Repeat for a long summarizer\n",
    "long_summarizer = pipeline(task=\"summarization\", model=\"cnicu/t5-small-booksum\", min_length=50, max_length=150)\n",
    "\n",
    "long_summary_text = long_summarizer(original_text)\n",
    "\n",
    "# Print the long summary\n",
    "print(long_summary_text[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05cc2ac4-aa4e-4202-a8eb-f680975f9207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 1: I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. The plot is centered around a young Swedish drama student named Lena\n",
      "Summary 2: \"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's political views are because this film can hardly be taken seriously on any level. I\n",
      "Summary 3: This film is interesting as an experiment but tells no cogent story. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless\n"
     ]
    }
   ],
   "source": [
    "# Create the list\n",
    "text_to_summarize = [w[\"text\"] for w in imdb]\n",
    "\n",
    "# Create the pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"cnicu/t5-small-booksum\", min_length=20, max_length=50)\n",
    "\n",
    "# Summarize each item in the list\n",
    "summaries = summarizer(text_to_summarize[:3], truncation=True)\n",
    "\n",
    "# Create for-loop to print each summary\n",
    "for i in range(0,3):\n",
    "  print(f\"Summary {i+1}: {summaries[i]['summary_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec5e3c6-94d6-480a-953d-587db8b06860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

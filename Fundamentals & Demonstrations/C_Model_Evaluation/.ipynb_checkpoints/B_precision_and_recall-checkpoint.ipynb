{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f779597f-d695-461c-8629-0ab641ad3b83",
   "metadata": {},
   "source": [
    "<h1>Precision and Recall</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa366a3-2fc2-4ce0-8255-18933462c661",
   "metadata": {},
   "source": [
    "<p><strong>precision</strong> refers to the percentage of positive results which are relevant and <strong>recall</strong> to the percentage of positive cases correctly classified.</p>\n",
    "\n",
    "<table border=\"1\">\n",
    "  <tr>\n",
    "      <th></th>\n",
    "      <th>Actual Positive</th>\n",
    "      <th>Actual Negative</th>\n",
    "  </tr>\n",
    "  <tr style=\"background-color: white;\">\n",
    "      <th>Predicted Positive</th>\n",
    "      <td style=\"background-color: lightblue;\">TP</td>\n",
    "      <td>FP</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <th>Predicted Negative</th>\n",
    "      <td>FN</td>\n",
    "      <td style=\"background-color: lightblue;\">TN</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<p>An example is given in the confusion matrix below</p>\n",
    "\n",
    "<table border=\"1\">\n",
    "  <tr>\n",
    "      <th></th>\n",
    "      <th>Actual Positive</th>\n",
    "      <th>Actual Negative</th>\n",
    "  </tr>\n",
    "  <tr style=\"background-color: white;\">\n",
    "      <th>Predicted Positive</th>\n",
    "      <td style=\"background-color: lightblue;\">233</td>\n",
    "      <td>65</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <th>Predicted Negative</th>\n",
    "      <td>109</td>\n",
    "      <td style=\"background-color: lightblue;\">480</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33593388-9d55-4502-8d85-95d8f9e6d3e2",
   "metadata": {},
   "source": [
    "<h3>Precision</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c99f227-279d-4464-90a8-40eab86734b8",
   "metadata": {},
   "source": [
    "<p>Precision is the percent of the model’s positive predictions that are correct.</p>\n",
    "\n",
    "$$Precision = \\frac{\\#\\: positives\\: predicted\\: correctly}{\\#\\: positive\\: predictions} = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "<p>The precision is then calculated as the following using the example confusion matrix above:</p>\n",
    "\n",
    "$$Precision = \\frac{\\#\\: positives\\: predicted\\: correctly}{\\#\\: positive\\: predictions} = \\frac{233}{233+65} = \\frac{233}{298} \\approx  0,78 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58d1e8a4-abf8-41be-a4e8-814155b6962c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7818791946308725\n"
     ]
    }
   ],
   "source": [
    "precision = 233 / (233 + 65)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a4098e-a313-4bbe-bda9-9b5d3e7ba7ba",
   "metadata": {},
   "source": [
    "<strong>Precision is a measure of how precise the model is with its positive predictions.</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc14abef-f8f9-4f2c-8222-f3d5e59c85b4",
   "metadata": {},
   "source": [
    "<h3>Recall</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6daad30-642b-4bad-8430-b33e1e0f2c3d",
   "metadata": {},
   "source": [
    "<p><strong>Recall</strong> is the percent of positive cases that the model predicts correctly.</p>\n",
    "\n",
    "<p>The recall is defined mathematically as the following:</p>\n",
    "\n",
    "$$Recall = \\frac{\\#\\: positives\\: predicted\\: correctly}{\\#\\: positive\\: cases} = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "<p>The recall is then calculated as the following using the example confusion matrix above:</p>\n",
    "\n",
    "$$Recall = \\frac{\\#\\: positives\\: predicted\\: correctly}{\\#\\: positive\\: predictions} = \\frac{233}{233+109} = \\frac{233}{531} \\approx  0,68 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "307eab83-38d2-4d98-8280-579f80bff895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6812865497076024\n"
     ]
    }
   ],
   "source": [
    "recall = 233 / (233 + 109)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfa6f8d-254e-47e4-ac03-567f24944568",
   "metadata": {},
   "source": [
    "<strong>Recall is a measure of how many of the positive cases the model can recall.</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd703533-204c-464d-95c6-72b43a5b4152",
   "metadata": {},
   "source": [
    "<h3>Precision & Recall Trade-off</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ed530b-1728-49c2-ac7e-273c004f52c4",
   "metadata": {},
   "source": [
    "<p>We often will be in a situation of choosing between increasing the recall (while lowering the precision) or increasing the precision (and lowering the recall). It will depend on the situation which we’ll want to maximize.</p>\n",
    "\n",
    "<p>For example, let’s say we’re building a model to predict if a credit card charge is fraudulent. The positive cases for our model are fraudulent charges and the negative cases are legitimate charges.</p>\n",
    "\n",
    "<p>Let’s consider two scenarios:</p>\n",
    "<strong>1. If we predict the charge is fraudulent, we’ll reject the charge.</strong><br />\n",
    "<strong>2. If we predict the charge is fraudulent, we’ll call the customer to confirm the charge.</strong>\n",
    "<br /><br />\n",
    "<p><strong>In case 1</strong>, it’s a huge inconvenience for the customer when the model predicts fraud incorrectly (a false positive). In <strong>In case 1</strong>, a false positive is a minor inconvenience for the customer.</p>\n",
    "\n",
    "<p>The higher the false positives, the lower the precision. Because of the high cost to false positives in the first case, it would be worth having a low recall in order to have a very high precision. <strong>In case 2</strong>, you would want more of a balance between precision and recall.</p>\n",
    "\n",
    "<strong>Note! That there’s no hard and fast rule on what values of precision and recall you’re shooting for. It always depends on the dataset and the application.</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5082f2-67f6-4a3c-a47b-c35e413a8c64",
   "metadata": {},
   "source": [
    "<h3>F1 Score</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f278739a-2b34-4051-bfaa-81c58c03e340",
   "metadata": {},
   "source": [
    "<p>Precision and recall are two numbers so it’s not always obvious how to choose between two models if one has a higher precision and the other has a higher recall.</p>\n",
    "\n",
    "<p>The <strong>F1 score</strong> is an average of precision and recall so that we have a single score for our model.</p>\n",
    "\n",
    "<p>The mathematical formula for the F1 score is:</p>\n",
    "\n",
    "$$F1 = 2\\:. \\frac{Precision\\:.Recall}{Precision + Recall}$$\n",
    "\n",
    "<p>Using the precision and recall numbers that we previously calculated. we can calculate the F1 score:</p>\n",
    "\n",
    "$$F1 = 2\\:. \\frac{ 0.78\\:.0.68}{0.78 + 0.68} \\approx 2\\:. \\frac{0,53}{1,46} \\approx 2\\:. 0,36 \\approx 0,72 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec6b503-a4a2-40d8-9765-ca9dd4ccc1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.728141703116457\n"
     ]
    }
   ],
   "source": [
    "f1_score = 2*(0.7819)*(0.6813) / (0.7819 + 0.6813)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515b77dd-10b3-47a7-acab-3e3bd5902874",
   "metadata": {},
   "source": [
    "<strong>The F1 score is the harmonic mean of the precision and recall values.</strong>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
